{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MHMSE41dCnWM",
        "outputId": "3deda477-9719-4ec5-c9a0-3eb0b304599b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1027369641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Before executing I have mount my google drive with google colab.\n",
        "\n",
        "#DATA PREPROCESSING\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "#step 1: Data Loading\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Real_Estate_Project/'\n",
        "IMAGE_DIR = os.path.join(PROJECT_DIR, 'images/')\n",
        "\n",
        "train_df = pd.read_excel(os.path.join(PROJECT_DIR, 'train(1).xlsx'))\n",
        "test_df = pd.read_excel(os.path.join(PROJECT_DIR, 'test2.xlsx'))\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "print(f\"Image directory: {IMAGE_DIR}\")\n",
        "\n",
        "#step2: Image mapping\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILDING IMAGE PATH MAPPING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def build_image_path_map(img_dir):\n",
        "\n",
        "    image_map = {}\n",
        "\n",
        "    # To Get all image files\n",
        "    all_files = os.listdir(img_dir)\n",
        "\n",
        "    for filename in tqdm(all_files, desc=\"Mapping images\"):\n",
        "\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        try:\n",
        "            property_id = int(base_name)\n",
        "            image_map[property_id] = os.path.join(img_dir, filename)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    return image_map\n",
        "\n",
        "IMAGE_PATH_MAP = build_image_path_map(IMAGE_DIR)\n",
        "print(f\"Mapped {len(IMAGE_PATH_MAP)} images\")\n",
        "\n",
        "# Step 3: VERIFYING IMAGES USING MAP\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VERIFYING IMAGES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_with_images = train_df[train_df['id'].isin(IMAGE_PATH_MAP.keys())].copy()\n",
        "test_with_images = test_df[test_df['id'].isin(IMAGE_PATH_MAP.keys())].copy()\n",
        "\n",
        "print(f\"\\nTrain images:\")\n",
        "print(f\"Found: {len(train_with_images)} / {len(train_df)}\")\n",
        "print(f\"Missing: {len(train_df) - len(train_with_images)}\")\n",
        "\n",
        "print(f\"\\nTest images:\")\n",
        "print(f\"Found: {len(test_with_images)} / {len(test_df)}\")\n",
        "print(f\"Missing: {len(test_df) - len(test_with_images)}\")\n",
        "\n",
        "train_df = train_with_images\n",
        "test_df = test_with_images\n",
        "\n",
        "print(f\"\\nFiltered to properties with images\")\n",
        "print(f\"Final train size: {len(train_df)}\")\n",
        "print(f\"Final test size: {len(test_df)}\")\n",
        "\n",
        "# STEP 4: Handling missing values\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HANDLING MISSING VALUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "missing_train = train_df.isnull().sum()\n",
        "if missing_train.sum() > 0:\n",
        "    print(\"\\nMissing values in train:\")\n",
        "    print(missing_train[missing_train > 0])\n",
        "else:\n",
        "    print(\"No missing values!\")\n",
        "\n",
        "# Handle missing values\n",
        "if 'view' in train_df.columns:\n",
        "    train_df['view'].fillna(0, inplace=True)\n",
        "    test_df['view'].fillna(0, inplace=True)\n",
        "\n",
        "if 'sqft_basement' in train_df.columns:\n",
        "    train_df['sqft_basement'].fillna(0, inplace=True)\n",
        "    test_df['sqft_basement'].fillna(0, inplace=True)\n",
        "\n",
        "if 'waterfront' in train_df.columns:\n",
        "    train_df['waterfront'].fillna(0, inplace=True)\n",
        "    test_df['waterfront'].fillna(0, inplace=True)\n",
        "\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
        "for col in numeric_cols:\n",
        "    if train_df[col].isnull().sum() > 0:\n",
        "        median_val = train_df[col].median()\n",
        "        train_df[col].fillna(median_val, inplace=True)\n",
        "        if col in test_df.columns:\n",
        "            test_df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "print(\"Missing values handled successfully.\")\n",
        "\n",
        "#Step 5: Feature Engineering\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_features(df):\n",
        "\n",
        "    if 'yr_built' in df.columns:\n",
        "        df['age'] = 2024 - df['yr_built']\n",
        "        df['age_squared'] = df['age'] ** 2\n",
        "\n",
        "    if 'yr_renovated' in df.columns:\n",
        "        df['is_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
        "        df['years_since_renovation'] = np.where(\n",
        "            df['yr_renovated'] > 0,\n",
        "            2024 - df['yr_renovated'],\n",
        "            df['age'] if 'age' in df.columns else 0\n",
        "        )\n",
        "\n",
        "    if 'sqft_living' in df.columns and 'sqft_lot' in df.columns:\n",
        "        df['living_lot_ratio'] = df['sqft_living'] / (df['sqft_lot'] + 1)\n",
        "\n",
        "    if 'sqft_above' in df.columns and 'sqft_living' in df.columns:\n",
        "        df['above_living_ratio'] = df['sqft_above'] / (df['sqft_living'] + 1)\n",
        "\n",
        "    if 'sqft_basement' in df.columns and 'sqft_living' in df.columns:\n",
        "        df['has_basement'] = (df['sqft_basement'] > 0).astype(int)\n",
        "        df['basement_ratio'] = df['sqft_basement'] / (df['sqft_living'] + 1)\n",
        "\n",
        "    if 'bedrooms' in df.columns and 'bathrooms' in df.columns:\n",
        "        df['bed_bath_ratio'] = df['bedrooms'] / (df['bathrooms'] + 0.5)\n",
        "        df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
        "\n",
        "    if 'bedrooms' in df.columns and 'sqft_living' in df.columns:\n",
        "        df['sqft_per_bedroom'] = df['sqft_living'] / (df['bedrooms'] + 1)\n",
        "\n",
        "    if 'sqft_living15' in df.columns and 'sqft_living' in df.columns:\n",
        "        df['living_vs_neighbors'] = df['sqft_living'] / (df['sqft_living15'] + 1)\n",
        "\n",
        "    if 'sqft_lot15' in df.columns and 'sqft_lot' in df.columns:\n",
        "        df['lot_vs_neighbors'] = df['sqft_lot'] / (df['sqft_lot15'] + 1)\n",
        "\n",
        "    if 'grade' in df.columns and 'condition' in df.columns:\n",
        "        df['quality_score'] = df['grade'] * df['condition']\n",
        "\n",
        "    if 'waterfront' in df.columns and 'view' in df.columns:\n",
        "        df['is_premium'] = ((df['waterfront'] == 1) | (df['view'] >= 3)).astype(int)\n",
        "\n",
        "    if 'grade' in df.columns:\n",
        "        df['is_luxury'] = (df['grade'] >= 11).astype(int)\n",
        "\n",
        "    if 'lat' in df.columns and 'long' in df.columns:\n",
        "        mean_lat = df['lat'].mean()\n",
        "        mean_long = df['long'].mean()\n",
        "        df['distance_from_center'] = np.sqrt(\n",
        "            (df['lat'] - mean_lat)**2 + (df['long'] - mean_long)**2\n",
        "        )\n",
        "\n",
        "    if 'floors' in df.columns:\n",
        "        df['is_multi_floor'] = (df['floors'] > 1).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = create_features(train_df)\n",
        "test_df = create_features(test_df)\n",
        "\n",
        "print(f\"Features engineered successfully.\")\n",
        "print(f\"New train shape: {train_df.shape}\")\n",
        "print(f\"New test shape: {test_df.shape}\")\n",
        "\n",
        "# step6 : Handling Outliers\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HANDLING OUTLIERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def remove_outliers(df, column, n_std=3):\n",
        "    mean = df[column].mean()\n",
        "    std = df[column].std()\n",
        "    df_filtered = df[(df[column] >= mean - n_std*std) & (df[column] <= mean + n_std*std)]\n",
        "    return df_filtered\n",
        "\n",
        "original_size = len(train_df)\n",
        "train_df = remove_outliers(train_df, 'price', n_std=3)\n",
        "print(f\"Removed {original_size - len(train_df)} price outliers\")\n",
        "\n",
        "train_df = remove_outliers(train_df, 'sqft_living', n_std=3)\n",
        "print(f\"Final train shape: {train_df.shape}\")\n",
        "\n",
        "#Step7: Feature Selection\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE SELECTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "exclude_cols = ['id', 'price', 'date', 'yr_built', 'yr_renovated', 'price_per_sqft']\n",
        "all_cols = train_df.select_dtypes(include=[np.number]).columns\n",
        "feature_cols = [col for col in all_cols if col not in exclude_cols]\n",
        "feature_cols = [col for col in feature_cols if col in test_df.columns]\n",
        "\n",
        "print(f\"Selected {len(feature_cols)} features\")\n",
        "\n",
        "X_train_full = train_df[feature_cols].copy()\n",
        "y_train_full = train_df['price'].copy()\n",
        "X_test = test_df[feature_cols].copy()\n",
        "\n",
        "train_full_property_ids = train_df['id'].tolist()\n",
        "test_property_ids = test_df['id'].tolist()\n",
        "\n",
        "#Step8: Training-Validation split(80:20)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN-VALIDATION SPLIT (80:20)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} ({len(X_train)/len(X_train_full)*100:.1f}%)\")\n",
        "print(f\"Validation set: {len(X_val)} ({len(X_val)/len(X_train_full)*100:.1f}%)\")\n",
        "\n",
        "train_property_ids = train_df.loc[X_train.index, 'id'].tolist()\n",
        "val_property_ids = train_df.loc[X_val.index, 'id'].tolist()\n",
        "\n",
        "print(f\"Sample train IDs: {train_property_ids[:5]}\")\n",
        "print(f\"Sample val IDs: {val_property_ids[:5]}\")\n",
        "\n",
        "\n",
        "#Step 9: Feature Scaling\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE SCALING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_cols, index=X_train.index)\n",
        "X_val_scaled = pd.DataFrame(X_val_scaled, columns=feature_cols, index=X_val.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)\n",
        "\n",
        "print(\"Features scaled using StandardScaler\")\n",
        "\n",
        "scaler_path = os.path.join(PROJECT_DIR, 'scaler.pkl')\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(f\"Scaler saved\")\n",
        "\n",
        "\n",
        "#Step10: Image Preprocessing\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"IMAGE PREPROCESSING SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(\"Transforms defined\")\n",
        "\n",
        "#Step11: Saving Preprocessing data with Image Map\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING PREPROCESSED DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "data_dict = {\n",
        "    'X_train': X_train_scaled,\n",
        "    'y_train': y_train,\n",
        "    'X_val': X_val_scaled,\n",
        "    'y_val': y_val,\n",
        "    'X_test': X_test_scaled,\n",
        "    'feature_cols': feature_cols,\n",
        "    'train_property_ids': train_property_ids,\n",
        "    'val_property_ids': val_property_ids,\n",
        "    'test_property_ids': test_property_ids,\n",
        "    'IMAGE_PATH_MAP': IMAGE_PATH_MAP,\n",
        "    'train_transform': train_transform,\n",
        "    'val_test_transform': val_test_transform,\n",
        "    'IMAGE_DIR': IMAGE_DIR,\n",
        "    'PROJECT_DIR': PROJECT_DIR,\n",
        "    'IMG_SIZE': IMG_SIZE\n",
        "}\n",
        "\n",
        "preprocessed_path = os.path.join(PROJECT_DIR, 'preprocessed_data.pkl')\n",
        "with open(preprocessed_path, 'wb') as f:\n",
        "    pickle.dump(data_dict, f)\n",
        "\n",
        "print(\"Preprocessed data saved!\")\n",
        "print(f\"Location: {preprocessed_path}\")\n",
        "\n",
        "#Step12: Generating Preprocessing summary\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n Dataset Statistics:\")\n",
        "print(f\"  - Training samples: {len(X_train_scaled)}\")\n",
        "print(f\"  - Validation samples: {len(X_val_scaled)}\")\n",
        "print(f\"  - Test samples: {len(X_test_scaled)}\")\n",
        "print(f\"  - Features: {len(feature_cols)}\")\n",
        "print(f\"  - Images mapped: {len(IMAGE_PATH_MAP)}\")\n",
        "\n",
        "print(f\"\\n Price Statistics:\")\n",
        "print(f\"  - Mean: ${y_train.mean():,.2f}\")\n",
        "print(f\"  - Median: ${y_train.median():,.2f}\")\n",
        "\n",
        "print(\"\\n PREPROCESSING COMPLETE!\")"
      ]
    }
  ]
}