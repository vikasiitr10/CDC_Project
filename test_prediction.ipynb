{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1o8rmn9MdSg"
      },
      "outputs": [],
      "source": [
        "# I have already mounted my google drive with colab and images for test data set is already present in my drive, for new test data set, we have to generate new images first.\n",
        "# GENERATING TEST PREDICTIONS\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.serialization.add_safe_globals([np.core.multiarray.scalar])\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATING TEST PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Real_Estate_Project/'\n",
        "\n",
        "\n",
        "# Step1: LOADING PREPROCESSING DATA FROM DRIVE\n",
        "\n",
        "\n",
        "print(\"\\nLoading preprocessing data...\")\n",
        "preprocessed_path = os.path.join(PROJECT_DIR, 'preprocessed_data.pkl')\n",
        "with open(preprocessed_path, 'rb') as f:\n",
        "    data_dict = pickle.load(f)\n",
        "\n",
        "X_test = data_dict['X_test']\n",
        "test_property_ids = data_dict['test_property_ids']\n",
        "IMAGE_PATH_MAP = data_dict['IMAGE_PATH_MAP']\n",
        "val_test_transform = data_dict['val_test_transform']\n",
        "IMG_SIZE = data_dict['IMG_SIZE']\n",
        "\n",
        "print(f\"Data loaded: {len(X_test)} test samples\")\n",
        "\n",
        "\n",
        "# STEP2: DEFINING OUR MODEL, SAME AS TRAINING\n",
        "\n",
        "\n",
        "print(\"\\nDefining model architecture...\")\n",
        "\n",
        "class MultimodalRealEstateModel(nn.Module):\n",
        "    def __init__(self, num_tabular_features, dropout_rate=0.3):\n",
        "        super(MultimodalRealEstateModel, self).__init__()\n",
        "\n",
        "        self.cnn = models.resnet18(pretrained=False)\n",
        "        num_cnn_features = self.cnn.fc.in_features\n",
        "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
        "\n",
        "        self.image_fc = nn.Sequential(\n",
        "            nn.Linear(num_cnn_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.tabular_fc = nn.Sequential(\n",
        "            nn.Linear(num_tabular_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        img_features = self.cnn(image)\n",
        "        img_features = img_features.view(img_features.size(0), -1)\n",
        "        img_features = self.image_fc(img_features)\n",
        "        tab_features = self.tabular_fc(tabular)\n",
        "        combined = torch.cat([img_features, tab_features], dim=1)\n",
        "        return self.fusion(combined)\n",
        "\n",
        "\n",
        "# STEP3: LOADING OUR BEST TRAINED MODEL FROM DRIVE\n",
        "\n",
        "\n",
        "print(\"\\nLoading trained model...\")\n",
        "\n",
        "num_features = X_test.shape[1]\n",
        "model = MultimodalRealEstateModel(num_features)\n",
        "\n",
        "\n",
        "if os.path.exists(os.path.join(PROJECT_DIR, 'best_model.pth')):\n",
        "    model_path = os.path.join(PROJECT_DIR, 'best_model.pth')\n",
        "else:\n",
        "    raise FileNotFoundError(\"No trained model found! Train the model first.\")\n",
        "\n",
        "checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded from: {model_path}\")\n",
        "print(f\"  Validation RMSE: ${checkpoint['val_rmse']:,.2f}\")\n",
        "print(f\"  Validation RÂ²: {checkpoint['val_r2']:.4f}\")\n",
        "\n",
        "\n",
        "# STEP4. CREATING OUR TEST DATASET, WE CAN DO THIS STEP BEFORE LOADING THE BEST MODEL\n",
        "\n",
        "print(\"\\nCreating test dataset...\")\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, tabular_data, property_ids, image_path_map, transform):\n",
        "        self.tabular_data = torch.FloatTensor(tabular_data.values)\n",
        "        self.property_ids = property_ids\n",
        "        self.image_path_map = image_path_map\n",
        "        self.transform = transform\n",
        "        self.blank_image = Image.new('RGB', (IMG_SIZE, IMG_SIZE), color=(128, 128, 128))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.property_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tabular = self.tabular_data[idx]\n",
        "        property_id = self.property_ids[idx]\n",
        "\n",
        "        img_path = self.image_path_map.get(property_id)\n",
        "\n",
        "        if img_path and os.path.exists(img_path):\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "            except:\n",
        "                image = self.blank_image\n",
        "        else:\n",
        "            image = self.blank_image\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, tabular, property_id\n",
        "\n",
        "test_dataset = TestDataset(X_test, test_property_ids, IMAGE_PATH_MAP, val_test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Test dataset ready: {len(test_dataset)} samples\")\n",
        "\n",
        "\n",
        "# STEP5. GENERATINF TEST PREDICTIONS\n",
        "\n",
        "\n",
        "print(\"\\nGenerating predictions...\")\n",
        "\n",
        "test_predictions = []\n",
        "test_ids = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, tabular, property_ids in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        images = images.to(device)\n",
        "        tabular = tabular.to(device)\n",
        "\n",
        "        outputs = model(images, tabular)\n",
        "\n",
        "        test_predictions.extend(outputs.cpu().numpy().flatten())\n",
        "        test_ids.extend(property_ids.numpy())\n",
        "\n",
        "print(f\"Generated {len(test_predictions)} predictions\")\n",
        "\n",
        "\n",
        "# 6. CREATING & SAVING OUR SUBMISSION FILE IN DRIVE IN CSV FORMAT\n",
        "\n",
        "\n",
        "print(\"\\nCreating submission file...\")\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'predicted_price': test_predictions\n",
        "})\n",
        "\n",
        "\n",
        "submission_df = submission_df.sort_values('id').reset_index(drop=True)\n",
        "\n",
        "\n",
        "submission_path = os.path.join(PROJECT_DIR, 'test_predictions.csv')\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "\n",
        "# 7. DISPLAYING RESULTS WITH SUMMARY\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUCCESSFULY! PREDICTIONS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nFile saved: {submission_path}\")\n",
        "print(f\"Total predictions: {len(submission_df)}\")\n",
        "\n",
        "print(f\"\\nPrice Statistics:\")\n",
        "print(f\"  Mean:   ${submission_df['predicted_price'].mean():>12,.2f}\")\n",
        "print(f\"  Median: ${submission_df['predicted_price'].median():>12,.2f}\")\n",
        "print(f\"  Min:    ${submission_df['predicted_price'].min():>12,.2f}\")\n",
        "print(f\"  Max:    ${submission_df['predicted_price'].max():>12,.2f}\")\n",
        "print(f\"  Std:    ${submission_df['predicted_price'].std():>12,.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Submission file is ready in drive!\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ]
    }
  ]
}