{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8evR1L7mHjyQ"
      },
      "outputs": [],
      "source": [
        "# I have already mounted my google drive with google colab before executing this code and using Colab T4:GPU to run this model.\n",
        "\n",
        "# MODEL TRAINING\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "#Step1: Loading Preprocessing Data\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING PREPROCESSED DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Real_Estate_Project/'\n",
        "preprocessed_path = os.path.join(PROJECT_DIR, 'preprocessed_data.pkl')\n",
        "\n",
        "with open(preprocessed_path, 'rb') as f:\n",
        "    data_dict = pickle.load(f)\n",
        "\n",
        "X_train = data_dict['X_train']\n",
        "y_train = data_dict['y_train']\n",
        "X_val = data_dict['X_val']\n",
        "y_val = data_dict['y_val']\n",
        "X_test = data_dict['X_test']\n",
        "train_property_ids = data_dict['train_property_ids']\n",
        "val_property_ids = data_dict['val_property_ids']\n",
        "test_property_ids = data_dict['test_property_ids']\n",
        "IMAGE_PATH_MAP = data_dict['IMAGE_PATH_MAP']\n",
        "train_transform = data_dict['train_transform']\n",
        "val_test_transform = data_dict['val_test_transform']\n",
        "IMG_SIZE = data_dict['IMG_SIZE']\n",
        "\n",
        "print(f\"Data loaded successfully.\")\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "print(f\"Image map size: {len(IMAGE_PATH_MAP)}\")\n",
        "\n",
        "# Step2: Optamizing Dataset classes using pre-built image path map.\n",
        "\n",
        "class FastMultimodalDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tabular_data, labels, property_ids, image_path_map, transform=None):\n",
        "        self.tabular_data = torch.FloatTensor(tabular_data.values)\n",
        "        self.labels = torch.FloatTensor(labels.values) if labels is not None else None\n",
        "        self.property_ids = property_ids\n",
        "        self.image_path_map = image_path_map\n",
        "        self.transform = transform\n",
        "\n",
        "        self.blank_image = Image.new('RGB', (IMG_SIZE, IMG_SIZE), color=(128, 128, 128))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.property_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # To get tabular data\n",
        "        tabular = self.tabular_data[idx]\n",
        "\n",
        "        # To get property ID\n",
        "        property_id = self.property_ids[idx]\n",
        "\n",
        "        img_path = self.image_path_map.get(property_id)\n",
        "\n",
        "        if img_path and os.path.exists(img_path):\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "            except:\n",
        "                image = self.blank_image\n",
        "        else:\n",
        "            image = self.blank_image\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "            return image, tabular, label\n",
        "        else:\n",
        "            return image, tabular, property_id\n",
        "\n",
        "# Creating datasets\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING DATASETS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_dataset = FastMultimodalDataset(\n",
        "    X_train, y_train, train_property_ids, IMAGE_PATH_MAP, train_transform\n",
        ")\n",
        "val_dataset = FastMultimodalDataset(\n",
        "    X_val, y_val, val_property_ids, IMAGE_PATH_MAP, val_test_transform\n",
        ")\n",
        "test_dataset = FastMultimodalDataset(\n",
        "    X_test, None, test_property_ids, IMAGE_PATH_MAP, val_test_transform\n",
        ")\n",
        "\n",
        "# Creating data loaders with optimized settings\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "print(f\"Datasets created\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "\n",
        "#Step 3: Defining The Model\n",
        "\n",
        "class MultimodalRealEstateModel(nn.Module):\n",
        "    def __init__(self, num_tabular_features, dropout_rate=0.3):\n",
        "        super(MultimodalRealEstateModel, self).__init__()\n",
        "\n",
        "        # Image branch (ResNet18)\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        for param in list(self.cnn.parameters())[:-20]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        num_cnn_features = self.cnn.fc.in_features\n",
        "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
        "\n",
        "        self.image_fc = nn.Sequential(\n",
        "            nn.Linear(num_cnn_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Tabular branch\n",
        "        self.tabular_fc = nn.Sequential(\n",
        "            nn.Linear(num_tabular_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Fusion layer\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        img_features = self.cnn(image)\n",
        "        img_features = img_features.view(img_features.size(0), -1)\n",
        "        img_features = self.image_fc(img_features)\n",
        "\n",
        "        tab_features = self.tabular_fc(tabular)\n",
        "        combined = torch.cat([img_features, tab_features], dim=1)\n",
        "        output = self.fusion(combined)\n",
        "        return output\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "model = MultimodalRealEstateModel(num_features, dropout_rate=0.3)\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"\\nModel initialized\")\n",
        "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "#Step4 : Training SetUp\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.cnn.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.image_fc.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.tabular_fc.parameters(), 'lr': 1e-3},\n",
        "    {'params': model.fusion.parameters(), 'lr': 1e-3}\n",
        "], weight_decay=1e-5)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=3\n",
        ")\n",
        "\n",
        "# Step5: Training Functions\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Training\")\n",
        "    for images, tabular, labels in pbar:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        tabular = tabular.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, tabular)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, tabular, labels in tqdm(loader, desc=\"Validating\"):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            tabular = tabular.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
        "\n",
        "            outputs = model(images, tabular)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            predictions.extend(outputs.cpu().numpy().flatten())\n",
        "            actuals.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "    r2 = r2_score(actuals, predictions)\n",
        "\n",
        "    return epoch_loss, rmse, mae, r2, predictions, actuals\n",
        "\n",
        "#Step6: Starting training Loop and saving the best model\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "EARLY_STOP_PATIENCE = 10\n",
        "\n",
        "best_val_rmse = float('inf')\n",
        "patience_counter = 0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_rmses = []\n",
        "val_r2s = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_loss, val_rmse, val_mae, val_r2, val_preds, val_actuals = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "    val_losses.append(val_loss)\n",
        "    val_rmses.append(val_rmse)\n",
        "    val_r2s.append(val_r2)\n",
        "\n",
        "    print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | RMSE: ${val_rmse:,.2f} | MAE: ${val_mae:,.2f} | R²: {val_r2:.4f}\")\n",
        "\n",
        "    scheduler.step(val_rmse)\n",
        "\n",
        "    if val_rmse < best_val_rmse:\n",
        "        best_val_rmse = val_rmse\n",
        "        best_val_r2 = val_r2\n",
        "        model_path = os.path.join(PROJECT_DIR, 'best_model.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_rmse': val_rmse,\n",
        "            'val_r2': val_r2\n",
        "        }, model_path)\n",
        "        print(f\"Best model saved! (RMSE: ${val_rmse:,.2f}, R²: {val_r2:.4f})\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= EARLY_STOP_PATIENCE:\n",
        "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"TRAINING COMPLETE!\")\n",
        "print(f\"Best RMSE: ${best_val_rmse:,.2f}\")\n",
        "print(f\"Best R²: {best_val_r2:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ]
}